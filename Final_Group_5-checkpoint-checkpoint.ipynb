{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7552eb-3086-4903-b6ea-223a6d541f66",
   "metadata": {},
   "source": [
    "## **BIKE SALES ANALYSIS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06430649-a181-4e1e-b466-d6fb246dda6f",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "This dataset provides a comprehensive overview of sales transactions, encompassing various dimensions such as customer demographics, product categories, and financial metrics. By analyzing this data, we can gain valuable insights into customer behaviour, product performance, and overall business trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca1a39c-7d8e-42de-bd5b-725ebe1ef1c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Problem statement \n",
    "The primary aim of this analysis is to understand the factors influencing sales performance and identify opportunities to optimize revenue and profitability.\n",
    "\n",
    "#### Aim\n",
    "- Identify key customer segments: Determine which customer demographics contribute most to sales and revenue.\n",
    "- Analyze product performance: Evaluate the performance of different model types\n",
    "- Understand seasonal trends: Identify seasonal patterns in revenue and profit.\n",
    "- Optimize pricing strategies: Analyze the impact of pricing on sales and profit margins.\n",
    "- Identify potential areas for improvements: Uncover opportunities to increase sales, reduce costs, and enhance customer satisfaction.\n",
    "- Identify how customer age affect order quantity.\n",
    "- Analyze geographic distribution of sales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c895f75c-9e0b-45ea-8478-9addfdc7ae65",
   "metadata": {},
   "source": [
    "## **DATA LOADING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b730077-e88e-4a61-8c39-54861cc90384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f112f156-f286-4a4a-bbd5-c14a3fa7b16d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'copied_new _date.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#load dataset\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m bike \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcopied_new _date.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m bike\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'copied_new _date.csv'"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "\n",
    "bike = pd.read_csv('copied_new _date.csv')\n",
    "bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62341039-c8d2-4383-bc7b-6411a6d01e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the original dataset\n",
    "df = bike.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471b96c4-4c7a-422a-90cf-3f5feab0608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the rows and columns of the dataset \n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3a7e33-0084-46f0-a3ce-3e9103a1b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the column titles\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95530e44-956f-458d-b728-614270b614bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brief info of dataset\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315b5614-294a-415e-bdda-2bbccf5da834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary statistics on dataset\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3517b3-3330-4d01-a623-6ec630219f4a",
   "metadata": {},
   "source": [
    "## Analysis Summary\n",
    "This analysis examines a dataset consisting of 214 observations, providing insights into its distribution, central tendency, and variability.\n",
    "\n",
    "Key Findings\n",
    "- Central Tendency: The mean value is 261,768.07, with a median of 261,760.50, indicating a slightly skewed distribution.\n",
    "- Variability: The standard deviation is 52.52, and the range spans from 261,695 to 261,867, demonstrating relatively low variability.\n",
    "- Distribution: The 25th percentile is 261,720.25, the 50th percentile (median) is 261,760.50, and the 75th percentile is 261,813.75.\n",
    "  \n",
    "Implications\n",
    "- The dataset's low variability suggests consistent data.\n",
    "- Column 3's constant value may indicate a control or baseline measure.\n",
    "- Correlations between columns could provide further insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226f71fc-6449-4611-a0c5-40ad38b2b0e5",
   "metadata": {},
   "source": [
    "## **DATA CLEANING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56690af6-d68b-4bf3-9493-228ca4fa177b",
   "metadata": {},
   "source": [
    "#### Identifying and Handling null/missing entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f8219-2ffb-4ac5-86d3-b79e8de2581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for number of null values in columns\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e41eff-e919-4430-8302-6f90e2f5fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying records with null values in Day Column\n",
    "\n",
    "df[df[\"Day\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a2403b-3c8d-47b6-a767-01af621dfb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the null values in rows\n",
    "\n",
    "df['Day'] = df['Day'].fillna(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7038d9d0-302f-4345-8211-18694a76f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify null values in Day column has been filled\n",
    "\n",
    "df[df[\"Day\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e7e63-0a19-4136-97ab-a210cbf999ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the null rows in Age_Group column\n",
    "\n",
    "df[df[\"Age_Group\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7472c40d-11d6-4cf6-8898-6082ce40ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling missing enteries in Age_Group column\n",
    "\n",
    "df['Age_Group'] = df['Age_Group'].fillna('[Adults (35-64)]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b614d35-bf93-44a0-8d28-6b75faaa2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify if null values in Age_Group column has been filled\n",
    "\n",
    "df[df[\"Age_Group\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a5298d-370d-4741-a207-81fbd3f303df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the null rows in Product_Description column\n",
    "\n",
    "df[df[\"Product_Description\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f02988-602b-425e-8278-13a256947c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the missing entry in the Product_Description column using Mode Imputation\n",
    "\n",
    "df['Product_Description']=df['Product_Description'].fillna('[Mountain-200 Silver, 38]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc3241e-883f-4bf2-8c3a-b736365483bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify if null values in the Product_Description column has been replaced with mode \n",
    "\n",
    "df[df[\"Product_Description\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa942a-09d9-4161-b278-b547f9bc80f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the most occuring product description\n",
    "\n",
    "df[\"Product_Description\"].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2a36d9-fdff-4858-b48c-fa1842532ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify null enteries in Order_Quantity  column has been filled\n",
    "\n",
    "df[df[\"Order_Quantity\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce070a99-a4c3-4728-91a6-48ee49971e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the null entry since there was no purchase for that particular row\n",
    "\n",
    "df.drop(index=22, inplace=True)\n",
    "df.drop(index=196, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6612d35f-a3d7-4178-8231-573c7cd75eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify record with null value has been dropped\n",
    "\n",
    "df[df[\"Order_Quantity\"].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9a3560-c793-4a5f-b58b-c50f3d9616ca",
   "metadata": {},
   "source": [
    "#### Handling Missing Values \n",
    "During data exploration, four columns were identified with missing values\n",
    "- Day (2 missing values)\n",
    "- Age Group (2 missing values)\n",
    "- Product Description (2 missing values)\n",
    "- Other Quantity (2 missing values)\n",
    "\n",
    "The following strategies were employed to handle missing values\n",
    "Day Column:\n",
    "- Utilized the existing Date column to extract the day and filled the missing values.\n",
    "Age Group Column\n",
    "- Analyzed the Age column to determine the corresponding age group and replaced missing values.\n",
    "Product Description Column\n",
    "- Employed mode imputation to fill missing values with the most frequent product description.\n",
    "Order Quantity Column\n",
    "- Removed entries with missing values, as they indicated no purchase (empty profit and cost columns) and removing them would not significant impact overall analysis.\n",
    "\n",
    "These strategies ensured data integrity and minimized potential biases as the dataset now contains no missing values, enabling reliable analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df92234-f699-4955-80a8-844446dfe5fe",
   "metadata": {},
   "source": [
    "#### Identifying and Removed duplicated entries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4b7981-b044-4502-becc-c6264e700cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the number of duplicate entries \n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbbb00f-b177-4beb-ade5-ce48c4fe55df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping duplicate\n",
    "\n",
    "df_new=df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72beb3db-88d4-426d-8b29-1f61123b4ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify duplicates afer dropping\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d0c455-a8ed-44e6-8abd-10f9944000fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the dimension of datset after dropping duplicates\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628f8bec-1dbc-413f-8aa8-3a9ab936d341",
   "metadata": {},
   "source": [
    "#### Remove Duplicates\n",
    "38 duplicates were identified and removed to ensure that each entry is unique. This cleanlinessin the data supports accurate analysis and reliable results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ae5c54-9ab3-47c3-94f1-33dba3c8ae6f",
   "metadata": {},
   "source": [
    "#### Identifying and splitting the appopriate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4d1051-39af-4e4c-a7d9-21d948f3d212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the Age_Group into Age_Group and Age_Range\n",
    "\n",
    "df[['Age_Grp', 'Age_Range']] =df['Age_Group'].str.split('(', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f5cb13-790c-4f31-940e-dea8543ba43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea589d-e85b-4eaf-82f2-49f78984c1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove \")\" from values in a column:\n",
    "\n",
    "df['Age_Range'] = df['Age_Range'].str.replace(')', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f372c-b65b-4f4a-903a-bea097f97d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec543fcf-3c64-4f0f-8a46-d78cf500c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the Product_Discription Model#, Color and Size\n",
    "\n",
    "df[[\"Model_num\",\"Color\",\"Size\"]] = df[\"Product_Description\"].str.split(expand=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c85fd7-f1b5-40b3-9e00-38e91c7a12fc",
   "metadata": {},
   "source": [
    "#### Identifying, splitting and Refining appopriate columns\n",
    "\n",
    "Age_Group Column Refining\n",
    "The Age_Group column contained age ranges with corresponding categories (e.g., \"Adults (35-64)\").\n",
    "To enhance analysis, the column was split into two separate columns:\n",
    "- Age Group: containing categories (Adults, Young Adults, Youth)\n",
    "- Age Range: containing numerical ranges (e.g. 35-64)\n",
    "\n",
    "Product Description Column Refining\n",
    "The Product Description column contained detailed product information (e.g., \"Model 200, Blue, 42\"). \n",
    "To facilitate analysis, the column was split into three separate columns:\n",
    "- Model: containing product model types\n",
    "- Colour: containing product colours\n",
    "- Size: containing product sizes\n",
    "\n",
    "The refined columns enable more precise analysis and easier data manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a848ff-92f7-4046-9640-a11537cb0ff6",
   "metadata": {},
   "source": [
    "#### Identifying and Dropping Unwanted Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a101c9-8f4c-4b78-80c4-36250afff5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping Date and Age_Range columns:\n",
    "\n",
    "df.drop(['Date', 'Age_Group','Product_Description','Product_Category','Year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816055c-199d-4d85-96d2-609c9d6ed971",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccb46b2-ea06-4c63-8732-16bba1727157",
   "metadata": {},
   "source": [
    "#### Dropping Unwanted Columns\n",
    "After refining the columns, several columns were identified as redundant or unnecessary and were dropped to enhance data efficiency.\n",
    "\n",
    "Dropped Columns:\n",
    "- Date: Dropped because the analysis focused on general trends, making specific dates irrelevant.\n",
    "- Age Group: Dropped after splitting into Age and Age Range, rendering the original column redundant.\n",
    "- Product Description: Dropped since it was split into Model Type, Colour, and Size, providing more granular information.\n",
    "- Product Category: Dropped as all entries belonged to the same category (\"Mountain Bikes\").\n",
    "- Year: Dropped since all entries shared the same year (\"2021\").\n",
    "\n",
    "The refined dataset now contains only relevant and unique columns, facilitating more accurate and efficient analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00647ab4-2576-434b-9a3a-f913da79d8e3",
   "metadata": {},
   "source": [
    "#### Identifying and Converting Columns to the appopriate dataypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6d558c-7c04-4a6b-a0eb-9ab1db50f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the datatypes of columns\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca556f-0b8e-4653-a021-856a1328faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Gender,Day and Order_Quantity column into appopriate data type\n",
    "\n",
    "df['Customer_Gender']= df['Customer_Gender'].astype('category')\n",
    "df['Day']=df['Day'].astype('int')\n",
    "df['Order_Quantity']=df['Order_Quantity'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d62218-c8b6-4300-9f11-3d19cbf63ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove \",\" and \"]\" from values in Color and Size column respectively\n",
    "\n",
    "df['Color'] = df['Color'].str.replace(',', '')\n",
    "df['Size'] = df['Size'].str.replace(']','')\n",
    "\n",
    "#Removing '$' and ',' from Unit_Cost, Unit_Price, Profit, Cost,Revenue columns\n",
    "df['Unit_Cost']= df['Unit_Cost'].str.replace('$','')\n",
    "df['Unit_Price']= df['Unit_Price'].str.replace('$','')\n",
    "df['Profit']= df['Profit'].str.replace('$','')\n",
    "df['Cost']= df['Cost'].str.replace('$','')\n",
    "df['Revenue']= df['Revenue'].str.replace('$','')\n",
    "\n",
    "df['Unit_Cost']= df['Unit_Cost'].str.replace(',','')\n",
    "df['Unit_Price']= df['Unit_Price'].str.replace(',','')\n",
    "df['Profit']= df['Profit'].str.replace(',','')\n",
    "df['Cost']= df['Cost'].str.replace(',','')\n",
    "df['Revenue']= df['Revenue'].str.replace(',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ea635-9050-4a1f-8a4e-9559b65a71f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Gender,Day and Order_Quantity column into categorical data type\n",
    "\n",
    "df['Revenue']=df['Revenue'].astype('float')\n",
    "df['Unit_Cost']=df['Unit_Cost'].astype('float')\n",
    "df['Unit_Price']=df['Unit_Price'].astype('float')\n",
    "df['Profit']=df['Profit'].astype('float')\n",
    "df['Cost']=df['Cost'].astype('float')\n",
    "\n",
    "df['Size']=df['Size'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f681259b-8d16-45c7-b241-6b93a413e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify if all columns are in their appopriate dat type\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b3cc5-eaa5-4d0d-8f49-d209e8d03ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Top rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd3f5d-40b3-463d-a558-b3106c86b884",
   "metadata": {},
   "source": [
    "#### Data Type Conversion\n",
    "\n",
    "During data exploration, it was discovered that several columns had incorrect data types, affecting analysis and calculations. \n",
    "To ensure data integrity, the following columns underwent data type conversion:\n",
    "\n",
    "Before conversion, the following cleaning operations were performed:\n",
    "- Removed commas from the \"Color Column\".\n",
    "- Removed trailing square brackets from the \"Size\" column.\n",
    "- Removed dollars and commas from \"Unit Cost\", \"Unit Price\", \"Profit\", \"Cost\", and \"Revenue\" columns.\n",
    "\n",
    "The following columns were converted to their appropriate data types:\n",
    "- \"Day\" column: Converted from float to integer.\n",
    "- \"Other Quantity\" column: Converted from float to integer.\n",
    "- \"Unit Cost\" column: Converted from object (string) to float.\n",
    "- \"Unit Price\" column: Converted from object (string) to float.\n",
    "- \"Profit\" column: Converted from object (string) to float.\n",
    "- \"Cost\" column: Converted from object (string) to float.\n",
    "- \"Revenue\" column: Converted from object (string) to float.\n",
    "- \"Size\" column: Converted from object (string) to integer.\n",
    "\n",
    "The dataset now has consistent and accurate data types, enabling reliable analysis and modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58adf5a2-c605-4dfe-8bdc-a89774f4e5e5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d73eaec-c56c-48b5-912b-61e16c6610fe",
   "metadata": {},
   "source": [
    "#### **DATA VISUALIZATION** \n",
    "Requirements\n",
    "\n",
    "- Python 3.x\n",
    "- Seaborn library (import seaborn as sns)\n",
    "- Matplotlib library (import matplotlib.pyplot as plt)\n",
    "- Pandas library (import pandas as pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3fe09d-4d85-4968-a71a-c9883794b79d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bd99d45-28ae-41f4-89b0-95dd542ca077",
   "metadata": {},
   "source": [
    "**DISTRIBUTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e8b90-a01b-4dad-a5a9-4d17368a57df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Define plot configuration\n",
    "figsize = (9, 15)\n",
    "bins = 10\n",
    "palette = sns.color_palette(\"viridis\", 5)\n",
    "\n",
    "# Create figure with five subplots\n",
    "fig, ax = plt.subplots(5, 1, figsize=figsize)\n",
    "\n",
    "# Define metrics\n",
    "metrics = [\"Unit_Cost\", \"Unit_Price\", \"Profit\", \"Cost\", \"Revenue\"]\n",
    "\n",
    "# Define a formatter to add commas for the x-axis labels\n",
    "comma_format = ticker.FuncFormatter(lambda x, _: f'{x:,.0f}')\n",
    "\n",
    "# Plot histograms\n",
    "for i, (metric, color) in enumerate(zip(metrics, palette)):\n",
    "    sns.histplot(df[metric], bins=bins, color=color, ax=ax[i], kde=True)\n",
    "    ax[i].set_title(f\"{metric} Distribution\", fontsize=15)\n",
    "    ax[i].set_xlabel(metric, fontsize=12)\n",
    "    ax[i].set_ylabel('Frequency', fontsize=12)\n",
    "    \n",
    "    # Remove scientific notation\n",
    "    ax[i].ticklabel_format(style='plain', axis='x')\n",
    "    \n",
    "    # Apply comma format to x-axis\n",
    "    ax[i].xaxis.set_major_formatter(comma_format)\n",
    "    \n",
    "    # Remove y-axis ticks\n",
    "    ax[i].yaxis.set_ticks([])\n",
    "    ax[i].set_yticklabels([])\n",
    "\n",
    "    # Remove grid lines\n",
    "    ax[i].grid(False)\n",
    "\n",
    "# Adjust layout and display plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb51b6b-c625-4b43-be3f-9961baf805a1",
   "metadata": {},
   "source": [
    "## Distribution Description\n",
    "- Profit Distribution\n",
    "  \n",
    "The profit distribution exhibits a right-skewed shape, indicating that most profits are moderate to low, with a peak around 500-1000. \n",
    "The long tail to the right suggests occasional high-profit values exceeding 5,000.Key statistics of mean 1,200, median of 900, and \n",
    "standard deviation of 1,500.The moderate to low profit margins emphasize the need for efficient cost management.\n",
    "\n",
    "- Cost Distribution\n",
    "  \n",
    "The cost distribution displays a right-skewed shape, indicating that most costs are moderate to low. \n",
    "The long tail to the right reveals occasional high-cost values.The high operational costs necessitate strategic cost optimization.\n",
    "\n",
    "- Revenue Distribution\n",
    "  \n",
    "The revenue distribution shows a right-skewed shape, indicating most revenues are moderate to low, with a peak around 1,000-2,000. \n",
    "The long tail to the right suggests occasional high-revenue values exceeding 10,000. Key statistics comprise a mean of 2,500, median of 1,800,\n",
    "and standard deviation of 2,000.Revenue potential is moderate to high, with opportunities for growth through targeted marketing and pricing strategies.\n",
    "\n",
    "- Unit Price Distribution\n",
    "  \n",
    "The unit price distribution exhibits a left-skewed shape, indicating most unit prices are moderate to high. \n",
    "The short tail to the left reveals few low-unit-price values.The competitive pricing strategy appears effective, with room for adjustments.\n",
    "\n",
    "- Unit Cost Distribution\n",
    "  \n",
    "The unit cost distribution exhibits a left-skewed shape, indicating most unit costs are moderate to high.\n",
    "The short tail to the left reveals few low-unit-cost values. High unit costs underscore the importance of efficient production or procurement processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba0bd38-86c9-4265-91af-7630b7246891",
   "metadata": {},
   "source": [
    "## *Box plot\n",
    "The Box plot visualizes the distribution of all data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82277e60-fd54-4a15-af75-044d5d4fb8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Get names of all numerical features\n",
    "num_vars = df.select_dtypes(include=['int', 'float']).columns.tolist()\n",
    "\n",
    "# Create a figure with subplots\n",
    "num_cols = len(num_vars)\n",
    "num_rows = num_cols\n",
    "fig, axes = plt.subplots(nrows=num_cols, ncols=2, figsize=(20, 4.5*num_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Define a color palette\n",
    "palette = sns.color_palette(\"viridis\", num_cols)\n",
    "\n",
    "# Define a formatter to add commas for the x-axis labels\n",
    "comma_format = ticker.FuncFormatter(lambda x, _: f'{x:,.0f}')\n",
    "\n",
    "# Create a boxplot for each numerical feature\n",
    "for i, (var, color) in enumerate(zip(num_vars, palette)):\n",
    "    sns.boxplot(x=df[var], ax=axes[i], color=color)\n",
    "    axes[i].set_title(var)\n",
    "    \n",
    "    # Apply the comma format to the x-axis\n",
    "    axes[i].xaxis.set_major_formatter(comma_format)\n",
    "    \n",
    "    # Remove grid lines\n",
    "    axes[i].grid(False)\n",
    "\n",
    "# Remove any extra empty subplots if needed\n",
    "if num_cols < len(axes):\n",
    "    for i in range(num_cols, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80af443-e3c1-4748-9954-4e136cf38ae6",
   "metadata": {},
   "source": [
    "## Outlier Analysis\n",
    "\n",
    "The analysis revealed that some distributions have outliers, while others appear normally distributed.\n",
    "\n",
    "Distributions without outliers include unit price, sales, day, and order quantity. These distributions are reasonable and consistent with expected patterns, indicating no unusual data points.\n",
    "\n",
    "On the other hand, distributions with outliers include revenue, size, cost, profit, customer age, and unit cost. The presence of outliers in these distributions is likely due to legitimate business transactions, such as large orders or bulk purchases, variations in customer demographics, and fluctuations in production or material costs.\n",
    "\n",
    "These outliers may represent legitimate business scenarios, such as wholesale orders, high-value transactions, or seasonal promotions. In contrast, \n",
    "the distributions without outliers likely represent typical business operations.\n",
    "\n",
    "Next steps include considering the business context when modeling or analyzing data, deciding whether to include or exclude outliers based on business requirements, and applying suitable data transformation or robust modeling techniques.\n",
    "\n",
    "By acknowledging the presence of outliers and understanding their potential causes, you can make informed decisions about data handling and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16faab65-3545-4c90-8338-8f2840b1a4b5",
   "metadata": {},
   "source": [
    "1. ## **Sales Analysis Charts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a54ec30-16c3-45f3-be31-5ffe844cb081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Define plot configuration\n",
    "fig, axs = plt.subplots(2, 3, figsize=(25, 12))\n",
    "\n",
    "# Define a green palette with 5 different shades of green\n",
    "colors = sns.color_palette(\"Greens\", 5)\n",
    "\n",
    "# Define a formatter to add commas for the y-axis labels\n",
    "comma_format = ticker.FuncFormatter(lambda x, _: f'{x:,.0f}')\n",
    "\n",
    "# Sales by Country\n",
    "region_sales = df.groupby('Country', observed=True)['Revenue'].sum().reset_index()\n",
    "region_sales = region_sales.sort_values(by='Revenue', ascending=False)  # Sort by Revenue\n",
    "axs[0, 0].bar(region_sales['Country'], region_sales['Revenue'], color=colors[0])\n",
    "axs[0, 0].set_xlabel('Country')\n",
    "axs[0, 0].set_ylabel('Total Sales')\n",
    "axs[0, 0].set_title('Sales by Country')\n",
    "axs[0, 0].tick_params(axis='x', rotation=45)\n",
    "axs[0, 0].yaxis.set_major_formatter(comma_format)  # Apply comma formatting to y-axis\n",
    "axs[0, 0].grid(False)  # Remove grid lines\n",
    "\n",
    "# Sales by Bike Type\n",
    "bike_type_sales = df.groupby('Sub_Category', observed=True)['Revenue'].sum().reset_index()\n",
    "bike_type_sales = bike_type_sales.sort_values(by='Revenue', ascending=False)  # Sort by Revenue\n",
    "axs[0, 1].bar(bike_type_sales['Sub_Category'], bike_type_sales['Revenue'], color=colors[1])\n",
    "axs[0, 1].set_xlabel('Bike Type')\n",
    "axs[0, 1].set_ylabel('Total Sales')\n",
    "axs[0, 1].set_title('Sales by Bike Type')\n",
    "axs[0, 1].tick_params(axis='x', rotation=45)\n",
    "axs[0, 1].yaxis.set_major_formatter(comma_format)  # Apply comma formatting to y-axis\n",
    "axs[0, 1].grid(False)  # Remove grid lines\n",
    "\n",
    "# Sales by Age Group\n",
    "age_group_sales = df.groupby('Age_Grp', observed=True)['Revenue'].sum().reset_index()\n",
    "age_group_sales = age_group_sales.sort_values(by='Revenue', ascending=False)  # Sort by Revenue\n",
    "axs[0, 2].bar(age_group_sales['Age_Grp'], age_group_sales['Revenue'], color=colors[2])\n",
    "axs[0, 2].set_xlabel('Age Group')\n",
    "axs[0, 2].set_ylabel('Total Sales')\n",
    "axs[0, 2].set_title('Sales by Age Group')\n",
    "axs[0, 2].tick_params(axis='x', rotation=45)\n",
    "axs[0, 2].yaxis.set_major_formatter(comma_format)  # Apply comma formatting to y-axis\n",
    "axs[0, 2].grid(False)  # Remove grid lines\n",
    "\n",
    "# Sales by Gender\n",
    "gender_sales = df.groupby('Customer_Gender', observed=True)['Revenue'].sum().reset_index()\n",
    "gender_sales['Customer_Gender'] = gender_sales['Customer_Gender'].cat.rename_categories({'M': 'Male', 'F': 'Female'})\n",
    "gender_sales = gender_sales.sort_values(by='Revenue', ascending=False)  # Sort by Revenue\n",
    "axs[1, 0].bar(gender_sales['Customer_Gender'], gender_sales['Revenue'], color=colors[3])\n",
    "axs[1, 0].set_xlabel('Gender')\n",
    "axs[1, 0].set_ylabel('Total Sales')\n",
    "axs[1, 0].set_title('Sales by Gender')\n",
    "axs[1, 0].tick_params(axis='x', rotation=45)\n",
    "axs[1, 0].yaxis.set_major_formatter(comma_format)  # Apply comma formatting to y-axis\n",
    "axs[1, 0].grid(False)  # Remove grid lines\n",
    "\n",
    "# Sales by Month\n",
    "month_sales = df.groupby('Month', observed=True)['Revenue'].sum().reset_index()\n",
    "month_sales = month_sales.sort_values(by='Revenue', ascending=False)  # Sort by Revenue\n",
    "axs[1, 1].bar(month_sales['Month'], month_sales['Revenue'], color=colors[4])\n",
    "axs[1, 1].set_xlabel('Month')\n",
    "axs[1, 1].set_ylabel('Total Sales')\n",
    "axs[1, 1].set_title('Sales by Month')\n",
    "axs[1, 1].tick_params(axis='x', rotation=45)\n",
    "axs[1, 1].yaxis.set_major_formatter(comma_format)  # Apply comma formatting to y-axis\n",
    "axs[1, 1].grid(False)  # Remove grid lines\n",
    "\n",
    "# Hide unused subplot\n",
    "fig.delaxes(axs[1, 2])\n",
    "\n",
    "# Layout so plots do not overlap\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8c602a-faa1-4e5a-88ed-bc5595151f3a",
   "metadata": {},
   "source": [
    "## **Sales Analysis Charts**\n",
    "\n",
    "The five bar charts provide insights into sales performance across different dimensions.\n",
    "\n",
    "Chart 1: Sales by Region\n",
    "The chart enables identification of top-performing regions, contributing significantly to overall sales revenue. Notably, the United States experienced the highest spike in sales revenue, indicating its position as a leading market. Conversely, Canada recorded the lowest sales revenue, highlighting potential areas for improvement.\n",
    "\n",
    "\n",
    "**Chart 2: Sales by Bike Type**\n",
    "\n",
    "This chart shows the total sales revenue by bike category (e.g., Mountain Bikes, Road Bikes).\n",
    "Key Insights\n",
    "Mountain Bikes experienced the highest spike in sales revenue, indicating their position as the most popular bike category.\n",
    "\n",
    "\n",
    "**Chart 3: Sales by Age Group**\n",
    "\n",
    "This chart illustrates the total sales revenue by customer age group (e.g., Adults, Youth).\n",
    "Adults experienced the highest spike in sales revenue, significantly outperforming other age groups.\n",
    "\n",
    "\n",
    "**Chart 4: Sales by Gender**\n",
    "\n",
    "- This chart presents the total sales revenue by customer gender.\n",
    "- The x-axis represents the genders, and the y-axis represents the total sales revenue.\n",
    "- The chart helps identify the gender with the highest sales.\n",
    "\n",
    "**Chart 5: Sales by Month**\n",
    "\n",
    "- This chart displays the total sales revenue by month.\n",
    "- The x-axis represents the months, and the y-axis represents the total sales revenue.\n",
    "- The chart helps identify seasonal sales trends.\n",
    "\n",
    "These charts provide valuable insights into sales performance, enabling businesses to make informed decisions \n",
    "about marketing strategies, product development, and resource allocation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b475a75-2f4c-41d2-8c4d-94a3d5f26aaa",
   "metadata": {},
   "source": [
    "# PIE CHART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b49e98-f7c9-4fd4-a434-9e32336e89d8",
   "metadata": {},
   "source": [
    "This pie chart visualizes the sales distribution by gender category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730648f6-d17c-4154-be3e-fde4b2a669f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a figure with a specified size\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Count occurrences of each gender in 'Customer_Gender'\n",
    "customer_gender_counts = df['Customer_Gender'].value_counts()\n",
    "\n",
    "# Map 'F' to 'Female' and 'M' to 'Male'\n",
    "labels = customer_gender_counts.index.map({'F': 'Female', 'M': 'Male'})\n",
    "\n",
    "# Use 'Set3' palette for more vibrant colors\n",
    "colors = sns.color_palette(\"Set3\", n_colors=2)\n",
    "\n",
    "# Create pie chart with new colors\n",
    "plt.pie(customer_gender_counts.values, labels=labels, colors=colors, autopct='%1.1f%%')\n",
    "\n",
    "# Set title\n",
    "plt.title('Sales Distribution by Gender Category')\n",
    "\n",
    "# Ensure pie chart is a circle\n",
    "plt.axis('equal')\n",
    "\n",
    "# Display pie chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff553b57-5cd8-488e-becd-53790aa2021e",
   "metadata": {},
   "source": [
    "The pie chart is a representative of proportion of Customers by Gender that purchased the bike.\n",
    "Female customers accounted for 55.5% whiles the Males customers accounted for 44.5% of the total customers.\n",
    "This indicates that the customers are predominantly females."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c93266b-02cf-40a4-8971-87ee96576019",
   "metadata": {},
   "source": [
    "# Box plot\n",
    "The Box plot visualizes the distribution of Order Quantity by Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b6cf83-b206-4947-b867-9c35ac440dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Boxplot of Order Quantity by Country\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Use the \"viridis\" palette for a vibrant look\n",
    "sns.boxplot(x='Country', y='Order_Quantity', data=df, palette=sns.color_palette(\"viridis\"))\n",
    "\n",
    "plt.title('Order Quantity Distribution by Country')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Order Quantity')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5923e21f-5a9c-4720-b5f8-abd627a59db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Group data by Country and calculate the mean Order Quantity, then sort by Order Quantity in descending order\n",
    "order_quantity_by_country = df.groupby('Country')['Order_Quantity'].mean().reset_index().sort_values(by='Order_Quantity', ascending=False)\n",
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Use the \"viridis\" palette for a vibrant look\n",
    "colors = sns.color_palette(\"viridis\", len(order_quantity_by_country))\n",
    "\n",
    "# Create a bar chart\n",
    "bars = plt.bar(order_quantity_by_country['Country'], order_quantity_by_country['Order_Quantity'], color=colors)\n",
    "\n",
    "# Add data labels on bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval, f'{yval:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Order Quantity Distribution by Country')\n",
    "plt.xlabel('Country')\n",
    "plt.gca().set_ylabel('')  # Remove y-axis label\n",
    "plt.gca().set_yticks([])  # Remove y-axis ticks\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig('country1.png')\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c5c10a-7519-4409-8c1b-1ef5fc46c773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6292f4a5-fec1-4118-8603-50f9feb5e9fb",
   "metadata": {},
   "source": [
    "## Boxplot Analysis Report\n",
    "\n",
    "##### Introduction\n",
    "\n",
    "This report presents an analysis of the boxplot for revenue data across different countries.\n",
    "The boxplot provides a visual representation of the distribution of revenue values, highlighting outliers, median values, and interquartile ranges.\n",
    "\n",
    "Key Findings\n",
    "\n",
    "Germany and Canada exhibited a few outliers, indicating unusual revenue values that deviate significantly from the rest of the data. \n",
    "The median revenue values for most countries clustered around the 50th percentile, suggesting a relatively consistent revenue performance.\n",
    "The interquartile range for the majority of countries was moderate, indicating a reasonable spread of revenue values.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "The boxplot analysis reveals that, except for Germany and Canada, the revenue data for most countries is relatively consistent and free of outliers. \n",
    "The identified outliers in Germany and Canada require further examination to determine their underlying causes.\n",
    "\n",
    "Recommendations\n",
    "\n",
    "It is recommended that further investigation be conducted to identify the causes of outliers in Germany and Canada.\n",
    "Additionally, revenue performance in these countries should be monitored to prevent future anomalies. \n",
    "Implementing measures to mitigate the impact of outliers is also suggested.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c2a047-6171-4cbf-8aa2-31b4372aad69",
   "metadata": {},
   "source": [
    "Interpret box plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2a122d-6a6c-4f8b-ab4a-c3d0553c328d",
   "metadata": {},
   "source": [
    "# Line Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c70fb1-4263-4ac4-aed9-6b38d2ad0c18",
   "metadata": {},
   "source": [
    "This line chart visualizes the monthly sales trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dce979-fb28-4d35-b8d4-5a19fa497fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'Month' column is in the correct order\n",
    "month_order = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \n",
    "               \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "df['Month'] = pd.Categorical(df['Month'], categories=month_order, ordered=True)\n",
    "\n",
    "# Group by 'Month' and calculate total sales\n",
    "monthly_sales = df.groupby('Month')['Revenue'].sum().reset_index()\n",
    "\n",
    "# Sort by month order after grouping\n",
    "monthly_sales = monthly_sales.sort_values(by='Month')\n",
    "\n",
    "# Line chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Customize lineplot\n",
    "sns.lineplot(\n",
    "    x='Month',\n",
    "    y='Revenue',\n",
    "    data=monthly_sales,\n",
    "    marker=\"o\",\n",
    "    markersize=10,\n",
    "    linestyle='-',\n",
    "    color='green'  # Change line color to green\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Monthly Sales Trend', fontsize=16)\n",
    "\n",
    "# Remove both x-axis and y-axis labels\n",
    "plt.gca().set_xlabel('')  # No x-axis label\n",
    "plt.gca().set_ylabel('')  # No y-axis label\n",
    "\n",
    "# Remove the entire y-axis\n",
    "plt.gca().get_yaxis().set_visible(False)\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "\n",
    "# Add data labels\n",
    "for x, y in zip(monthly_sales['Month'], monthly_sales['Revenue']):\n",
    "    plt.annotate(f\"{y:,.0f}\", (x, y), textcoords=\"offset points\", xytext=(0,5), ha='center')\n",
    "\n",
    "# Remove grid lines\n",
    "plt.grid(False)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e32dfa-b918-41cb-8250-48b414d5582e",
   "metadata": {},
   "source": [
    "### Interpretation and Documentation\n",
    "\n",
    "The provided chart visualizes the monthly sales data over a year. We observe a general upward trend with notable peaks in September and December. This suggests that the business experiences increased sales during these months, potentially due to seasonal factors like holiday shopping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc361114-7a9d-4559-977f-52d1ab500b25",
   "metadata": {},
   "source": [
    "# Scatter Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ae3314-1f84-4c19-a114-409a0381f3b6",
   "metadata": {},
   "source": [
    "The scatter plot visualizes the correlation between Customer Age and Order Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354b1e5-146c-4801-bbf2-60eb9a6bcacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Group by 'Customer_Age' and calculate average 'Order_Quantity'\n",
    "grouped_data = df.groupby('Customer_Age')['Order_Quantity'].mean().reset_index()\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(grouped_data['Customer_Age'], grouped_data['Order_Quantity'], \n",
    "             c=grouped_data['Order_Quantity'], cmap='viridis', s=100, alpha=0.75)\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Average Order Quantity')\n",
    "plt.title('Customer Age vs. Average Order Quantity')\n",
    "\n",
    "# Add a color bar for the viridis palette\n",
    "plt.colorbar(label='Order Quantity')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696aa3d3-2c68-44fa-abb1-543afed32427",
   "metadata": {},
   "source": [
    "## Customer Age vs. Average Order Quantity\n",
    "This scatter plot visualizes the relationship between customer age and average order quantity. It shows a distribution of data points, representing the average order quantity for different customer age groups. However, without further analysis, it is difficult to draw definitive conclusions about the relationship between age and order quantity.\n",
    "No Strong Correlation, the plot doesn't indicate a strong linear relationship between age and order quantity but there is significant variability in order quantities within each age group.\n",
    "\n",
    "#### Recommendations:\n",
    "The scatter plot doesn't show a clear link between age and order quantity. However, you can still use age to target customers with specific offers and products. Here are some recommendations:\n",
    "\n",
    "- Segment your customers: Group customers by age to tailor marketing efforts.\n",
    "- Personalize marketing: Use customer data to create targeted campaigns.\n",
    "- Offer diverse products: Provide a range of products to appeal to different age groups.\n",
    "- Consider product bundling: Combine products to increase average order value.\n",
    "- Use age-based and seasonal promotions: Offer discounts and deals to specific age groups.\n",
    "- Provide excellent customer service: Offer personalized service across all channels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975cdd35-e3e0-479c-914a-c199fd34c113",
   "metadata": {},
   "source": [
    "# Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35118608-5302-4110-8ff6-be0b3c089f51",
   "metadata": {},
   "source": [
    "The heatmap visualizes the correlation matrix of sales order, year, customer age, and revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee8cc67-77b0-4f37-826d-378df6947a00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = df.select_dtypes(include=['int64', 'float64']).corr()\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Draw the heatmap with the 'coolwarm' palette\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='viridis', linewidths=0.5)\n",
    "\n",
    "# Set the title\n",
    "plt.title('Correlation Matrix', fontsize=16)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db41e53-2e14-4beb-bfc3-454f0fb42298",
   "metadata": {},
   "source": [
    "#### Correlation Matrix Interpretation\n",
    "\n",
    "The correlation matrix you provided is a visual representation of how different variables in your dataset are related to each other. The color intensity and direction of the squares indicate the strength and direction of the correlation.\n",
    "Key Observations:\n",
    " * Strong Positive Correlations:\n",
    "   * Unit Cost and Unit Price: There's a very strong positive correlation between these two variables (0.96). This suggests that as the unit cost increases, the unit price also tends to increase.\n",
    "   * Profit and Cost: A strong positive correlation (0.98) exists between profit and cost. This implies that higher costs often lead to higher profits, possibly due to higher sales prices or increased sales volume.\n",
    "   * Cost and Revenue: A very strong positive correlation (0.99) indicates that higher costs are associated with higher revenue, likely due to increased sales or higher selling prices.\n",
    " * Moderate Positive Correlations:\n",
    "   * Customer Age and Profit: There's a moderate positive correlation (0.13) between customer age and profit. This suggests that older customers might tend to make larger purchases or opt for higher-margin products.\n",
    " * Weak or No Correlation:\n",
    "   * Sales Order Number and Other Variables: The Sales Order Number appears to have very weak or no correlation with other variables, indicating that it's not a significant factor influencing the other variables.\n",
    "Implications for Analysis:\n",
    " * Multicollinearity: The strong correlations between 'Unit Cost' and 'Unit Price', 'Profit' and 'Cost', and 'Cost' and 'Revenue' suggest potential multicollinearity issues. This can affect the accuracy and stability of statistical models. Consider addressing this by removing one of the highly correlated variables or using techniques like Principal Component Analysis (PCA).\n",
    " * Feature Importance: 'Unit Cost' and 'Unit Price' seem to be crucial for predicting 'Profit' and 'Revenue'. 'Customer Age' might also be a relevant factor to consider in further analysis.                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6b2eb-1027-407e-af80-716a2dcd1826",
   "metadata": {},
   "source": [
    "#### **DATA ANALYSIS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae866d83-6548-4067-b7fe-ae0a8259fe66",
   "metadata": {},
   "source": [
    "2. #### Analyzing Product Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957f48af-968f-4ea7-b9a2-5a0caf829f6e",
   "metadata": {},
   "source": [
    " Product Category Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0946f203-7208-45ff-bd86-05384889aa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Group data by Model_num, calculate sum of revenue, and sort by Revenue in ascending order\n",
    "category_sales = df.groupby('Model_num')['Revenue'].sum().reset_index().sort_values(by='Revenue', ascending=True)\n",
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Use the 'viridis' palette for colors\n",
    "colors = sns.color_palette(\"viridis\", len(category_sales))\n",
    "\n",
    "# Horizontal bar chart with shades of colors\n",
    "plt.barh(category_sales['Model_num'], category_sales['Revenue'], color=colors)\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Revenue by Model_Num Type', fontsize=16)\n",
    "plt.gca().set_xlabel('')  # Remove x-axis label\n",
    "plt.gca().set_xticks([])  # Hide x-axis ticks\n",
    "\n",
    "# Add data labels next to each bar\n",
    "for index, value in enumerate(category_sales['Revenue']):\n",
    "    plt.text(value, index, f\"{value:,.0f}\", va='center')  # Display data label\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a3a1e-cfb7-4cd3-81f5-ba30e1bfddd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24d08611-7273-4b2d-b04c-d4d02040ca27",
   "metadata": {},
   "source": [
    "The Mountain-200 model generated the highest revenue among all model types, reaching (385,680.00), whereas the Road-700 model produced the least revenue at just ($1,650.00). \n",
    "This disparity highlights a significant gap in revenue generation between the two models, suggesting that the Mountain-200 has stronger market appeal or possibly a higher price point that drives more sales compared to the Road 700. \n",
    "This insight might indicate a need to analyze factors behind the Road-700’s lower performance, such as market demand, pricing strategy, or promotional efforts, to identify areas for potential revenue growth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb5276e-49fc-4a4a-9040-e0be0c85a824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Profit Margin Analysis\n",
    "# Group data by product category, calculate sum of profit\n",
    "profit_margin = df.groupby('Model_num')['Profit'].sum().reset_index()\n",
    "\n",
    "# Sort by profit values in descending order\n",
    "profit_margin = profit_margin.sort_values(by='Profit', ascending=False)\n",
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Define the color for the first bar and shades of green for the rest\n",
    "colors = ['darkgreen'] + sns.color_palette(\"Greens\", len(profit_margin) - 1)\n",
    "\n",
    "# Plot bar chart with the custom color palette\n",
    "bars = plt.bar(profit_margin['Model_num'], profit_margin['Profit'], color=colors, width=0.7)\n",
    "\n",
    "# Add data labels on bars with commas\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval, f'{yval:,.0f}', ha='center', va='bottom')\n",
    "\n",
    "# Customize plot\n",
    "plt.xlabel('Model Number', fontsize=14)\n",
    "plt.title('Profit Margin Analysis', fontsize=16)\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks([])  # Remove y-axis ticks\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5cc246-b968-4e31-8a42-b27607d9c45d",
   "metadata": {},
   "source": [
    "##### Profit Margin Analysis by Bike Model\n",
    "This bar chart shows the profit margin for each bike model category, highlighting the profit each one generates after covering costs.\n",
    "##### Key Insights:\n",
    "- Top Performer: Mountain-200 stands out for its high profitability and lower costs, generating 179,086 in profit.\n",
    "- Second Best Performer: Road-300 follows with a profit of 25,140. With proper monitoring and management, it has the potential to perform as well as the top model.\n",
    "- Needs Attention: Mountain-700 has the lowest profit margin, bringing in only $770, suggesting it may be a candidate for discontinuation.\n",
    "- Viewing these margins side by side helps identify which models are performing well and where there’s room for growth. This analysis serves as a valuable guide for focusing resources, boosting profits, and making strategic decisions on which bikes to continue producing.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2d1826-ad49-4762-9ed8-dedbb28fa0a4",
   "metadata": {},
   "source": [
    "3. #### Understanding Seasonal Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0709c96-19d8-4892-80f3-8a10912ffb35",
   "metadata": {},
   "source": [
    "The provided chart visualizes the monthly revenue data over a year. We observe a general upward trend with notable peaks in September and December. This suggests that the business experiences increased sales during these months, potentially due to seasonal factors like holiday shopping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95f05a7-de52-4821-b014-f0e0d0b30c94",
   "metadata": {},
   "source": [
    "4. #### **Optimizing Pricing Strategies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f974c3f-2af5-4fca-83e1-5d062a3581f6",
   "metadata": {},
   "source": [
    "#### Analyzing the Impact of pricing on Revenue and Profit \n",
    "\n",
    "#### Create a line plot \n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set_style(\"white\")  # Set a clean background style\n",
    "\n",
    "sns.lineplot(x='Unit_Price', y='Revenue', data=df, color='darkblue', label='Revenue')\n",
    "sns.lineplot(x='Unit_Price', y='Profit', data=df, color='royalblue', label='Profit')\n",
    "\n",
    "##### Customize the plot\n",
    "plt.xlabel('Unit_Price')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Impact of Pricing on Revenue and Profit')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12f28d2-7f8d-49c2-b242-4ccc354f5d62",
   "metadata": {},
   "source": [
    "#### Interpretation of the Chart\n",
    "This line graph shows the relationship between Unit Price and Revenue/Profit.\n",
    "I was observed that:\n",
    " * Revenue and Profit both generally increase with Unit Price: This suggests that higher-priced products tend to generate more revenue and profit.\n",
    " * Revenue seems to have a stronger positive correlation with Unit Price than Profit: This could indicate that while higher prices lead to more revenue, the associated costs might also increase, affecting the overall profit.\n",
    " * \n",
    " * Revenue and Profit lines diverge at higher Unit Prices: This could be due to factors like increased production costs, higher marketing expenses, or diminishing returns on higher prices.\n",
    " * Fluctuations and Peaks: The lines show some variability, which could be due to various factors like seasonal trends, promotional activities, or changes in market demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8ee521-2506-49dc-9759-79a590d76d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does 'Customer_Gender' affect 'Order_Quantity'\n",
    "gender_order_quantity = df.groupby('Customer_Gender', observed=True)['Order_Quantity'].mean().reset_index()\n",
    "\n",
    "# Update 'Customer_Gender' labels\n",
    "gender_order_quantity['Customer_Gender'] = gender_order_quantity['Customer_Gender'].map({'F': 'Female', 'M': 'Male'})\n",
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Create a bar plot with shades of color using the 'Greens' palette\n",
    "sns.barplot(x='Customer_Gender', y='Order_Quantity', data=gender_order_quantity, palette='Greens')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Customer Gender')\n",
    "plt.ylabel('')  # Remove y-axis label\n",
    "plt.gca().get_yaxis().set_visible(False)  # Remove the entire y-axis\n",
    "plt.title('Customer Gender vs. Average Order Quantity')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Add data labels on bars with two decimal points\n",
    "for i, (gender, order_quantity) in enumerate(zip(gender_order_quantity['Customer_Gender'], gender_order_quantity['Order_Quantity'])):\n",
    "    plt.text(i, order_quantity, f\"{order_quantity:.2f}\", ha='center', va='bottom')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8038c73a-d8c9-4354-8223-7d400743fd40",
   "metadata": {},
   "source": [
    "### Customer Gender vs. Average Order Quantity\n",
    "\n",
    "To highlight differences in purchasing behaviour, the bar graph above clearly shows that female customers have a higher average order quantity compared to male customers. This insight can be valuable for understanding gender-based purchasing behaviours and tailoring marketing strategies accordingly.\n",
    "With this, businesses can leverage this information to design targeted promotions and improve customer engagement based on gender-specific trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee986f8c-aa18-4bfd-8f94-e4c27ba8de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPOTHESIS TESTING: \n",
    "# Check if country has significant impact on revenue\n",
    "\n",
    "# NULL HYPOTHESIS (H0): Country does NOT have a significant impact on revenue.\n",
    "# ALTERNATIVE HYPOTHESIS (H1): Country DOES have a significant impact on revenue.\n",
    "\n",
    "countries = df['Country'].unique()\n",
    "revenues = [df[df['Country'] == country]['Revenue'] for country in countries]\n",
    "\n",
    "# Perform ANOVA test\n",
    "f_stat, p_val = f_oneway(*revenues)\n",
    "\n",
    "print(\"ANOVA Test Results:\")\n",
    "print(\"F-statistic:\", f_stat)\n",
    "print(\"p-value:\", p_val)\n",
    "\n",
    "# Interpret results\n",
    "alpha = 0.05  # Significance level\n",
    "if p_val < alpha:\n",
    "    print(\"Reject null hypothesis: Country has significant impact on revenue.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis: Country does not have significant impact on revenue.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a99a6b-a502-411e-8974-a563be03a5c8",
   "metadata": {},
   "source": [
    "## HYPOTHESIS TESTING\n",
    "##### **ANOVA Test Results: Country Impact on Revenue**\n",
    "\n",
    "##### **Test Objective**:\n",
    "To determine if there is a significant difference in revenue between countries.\n",
    "\n",
    "##### **Test Methodology**:\n",
    "Analysis of Variance (ANOVA) test was performed using the f_oneway function from the scipy.stats library.\n",
    "\n",
    "##### **Test Results**:\n",
    "\n",
    "- F-statistic: 3.6884547612739564\n",
    "- p-value: 0.003414496281222786\n",
    "\n",
    "##### **Conclusion**:\n",
    "The null hypothesis, stating that there is no significant difference in revenue between countries, was rejected (p-value < 0.05). This indicates that country has a statistically significant impact on revenue.\n",
    "\n",
    "##### **Interpretation**:\n",
    "The significant difference in revenue between countries suggests that geographical location plays a role in determining revenue. Further analysis is required to understand the nature of these differences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2664b9-800d-40cf-928b-b3e21a658a67",
   "metadata": {},
   "source": [
    "#### **RECOMMENDATIONS**\n",
    "\n",
    "- Targeted Marketing: Develop marketing campaigns focused on female customers, as they tend to place larger orders.\n",
    "- Product Recommendations: Use this insight to offer personalized product recommendations to female customers, potentially increasing sales.\n",
    "- Pricing Strategy: The company might consider optimizing their pricing strategy to balance revenue and profit. Some products might be more profitable at higher prices, while others might require lower prices to attract customers.\n",
    "- Cost Management: Analyzing the factors contributing to the divergence of Revenue and Profit at higher prices could help identify areas for cost reduction or efficiency improvements.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3018c9e-61e1-4672-bfb3-5365e0217eb0",
   "metadata": {},
   "source": [
    "### MACHINE LEARNING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa67cfd-38c7-4bbf-8baf-4e406e1d7bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50f0176-4879-4ab3-ada7-74bb6d0df43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5279cd8d-5e4a-4f2d-8e86-0548c449dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select columns of interest\n",
    "columns_of_interest = ['Model_num', 'Size', 'Color', 'Month', 'Unit_Price', 'Order_Quantity', 'Cost']\n",
    "df_selected = df[columns_of_interest]\n",
    "\n",
    "# Ensure 'Price' is numerical\n",
    "df_selected.loc[:, 'Unit_Price'] = pd.to_numeric(df_selected['Unit_Price'])\n",
    "\n",
    "\n",
    "# Define categorical and numerical columns\n",
    "categorical_cols = ['Model_num', 'Color', 'Month']\n",
    "numerical_cols = ['Size','Order_Quantity','Cost']\n",
    "\n",
    "# Preprocess categorical columns\n",
    "le = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "   df_selected.loc[:, col] = le.fit_transform(df_selected[col])\n",
    "\n",
    "\n",
    "# Scale numerical columns\n",
    "scaler = StandardScaler()\n",
    "df_selected.loc[:, numerical_cols] = scaler.fit_transform(df_selected[numerical_cols])\n",
    "\n",
    "\n",
    "# Define X (features) and y (target)\n",
    "X = df_selected.drop('Unit_Price', axis=1)  # Features: Model Number, Size, Color, Month\n",
    "y = df_selected['Unit_Price']  # Target: Price\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5207a8-01d3-4843-b720-a001b271f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting our data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31ae460-c64c-41b2-b619-0db44ed883a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the linear regression model\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5787c2-939b-4435-9767-965ca7653cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train our linear regression model\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9069fce2-0dd6-4ebc-838a-b58a482a0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5675e3ab-a8b9-452b-a807-306097c8edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccc9008-3e5a-448a-b509-7ce01abb95eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the error that exist between predicted values and actual values\n",
    "\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d2fe69-e285-43b3-bf31-9fe2a8322e5e",
   "metadata": {},
   "source": [
    "## Testing Various Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91818af-a1bc-468a-bafb-87ca5bcc2356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.25)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# SVR\n",
    "svr = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Neural Network\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(50, 50), max_iter=1000)\n",
    "mlp.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2793a452-5efb-4243-8de9-d83a5ee10d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assume y_test and y_pred_lr are already defined\n",
    "\n",
    "# Print Linear Regression metrics\n",
    "print(\"Linear Regression:\")\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"MSE: {mse_lr:.2f}\")\n",
    "print(f\"MAE: {mae_lr:.2f}\")\n",
    "print(f\"R²: {r2_lr:.2f}\")\n",
    "\n",
    "# Create a figure and axis for the scatter plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Scatter plot of actual vs. predicted values\n",
    "ax.scatter(y_test, y_pred_lr, label='Predictions', color='green', alpha=0.7)\n",
    "\n",
    "# Plot perfect prediction line (45-degree line)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', label='Perfect Prediction')\n",
    "\n",
    "# Set labels and title with Linear Regression performance metrics\n",
    "ax.set_xlabel('Actual Values')\n",
    "ax.set_ylabel('Predicted Values')\n",
    "ax.set_title(f'Linear Regression Performance\\nMSE: {mse_lr:.2f}, MAE: {mae_lr:.2f}, R²: {r2_lr:.2f}')\n",
    "\n",
    "# Legend\n",
    "ax.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cba44ac-cdcc-4a84-92e4-a7ea0c22c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ridge Regression:\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_ridge)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_ridge)}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred_ridge)}\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Assume y_test and y_pred_ridge are already defined\n",
    "\n",
    "# Print Ridge Regression metrics\n",
    "print(\"Ridge Regression:\")\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "print(f\"MSE: {mse_ridge:.2f}\")\n",
    "print(f\"MAE: {mae_ridge:.2f}\")\n",
    "print(f\"R²: {r2_ridge:.2f}\")\n",
    "\n",
    "# Create a figure and axis for the scatter plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Scatter plot of actual vs. predicted values in green\n",
    "ax.scatter(y_test, y_pred_ridge, label='Predictions', color='green', alpha=0.7)\n",
    "\n",
    "# Plot perfect prediction line (45-degree line)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', label='Perfect Prediction')\n",
    "\n",
    "# Set labels and title with Ridge Regression performance metrics\n",
    "ax.set_xlabel('Actual Values')\n",
    "ax.set_ylabel('Predicted Values')\n",
    "ax.set_title(f'Ridge Regression Performance\\nMSE: {mse_ridge:.2f}, MAE: {mae_ridge:.2f}, R²: {r2_ridge:.2f}')\n",
    "\n",
    "# Legend\n",
    "ax.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f2bc73-7233-4d1e-bb3a-4f84396b4133",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gradient Boosting:\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_gb)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_gb)}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred_gb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6080ae5b-4aa0-4ecb-86b0-a866fc1eb729",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Assume y_test and y_pred_rf are already defined\n",
    "\n",
    "# Print Random Forest metrics\n",
    "print(\"Random Forest:\")\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"MSE: {mse_rf:.2f}\")\n",
    "print(f\"MAE: {mae_rf:.2f}\")\n",
    "print(f\"R²: {r2_rf:.2f}\")\n",
    "\n",
    "# Create a figure and axis for the scatter plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Scatter plot of actual vs. predicted values in green\n",
    "ax.scatter(y_test, y_pred_rf, label='Predictions', color='green', alpha=0.7)\n",
    "\n",
    "# Plot perfect prediction line (45-degree line)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', label='Perfect Prediction')\n",
    "\n",
    "# Set labels and title with Random Forest performance metrics\n",
    "ax.set_xlabel('Actual Values')\n",
    "ax.set_ylabel('Predicted Values')\n",
    "ax.set_title(f'Random Forest Performance\\nMSE: {mse_rf:.2f}, MAE: {mae_rf:.2f}, R²: {r2_rf:.2f}')\n",
    "\n",
    "# Legend\n",
    "ax.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707be50a-823a-423a-82ed-cbff4d501dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Support Vector Regression:\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_svr)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_svr)}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred_svr)}\")\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f5385-73e1-4add-94d3-f5b4f2d1f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVR\n",
    "svr = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr.fit(X_train, y_train)\n",
    "print(\"Support Vector Regression:\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_svr)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_svr)}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred_svr)}\")\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d18e875-2555-4a32-b159-864e7454c473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e02f87-0a38-45fd-b874-d2484e087a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Neural Network:\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_mlp)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_mlp)}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred_mlp)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddbff6a-9139-40d7-9e67-73e1abcdeb43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5929fdf-5b49-41bb-8a40-6a1754caaa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Assume y_test and y_pred_svr are already defined\n",
    "\n",
    "# Print SVR metrics\n",
    "print(\"Support Vector Regression:\")\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "mae_svr = mean_absolute_error(y_test, y_pred_svr)\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "\n",
    "print(f\"MSE: {mse_svr:.2f}\")\n",
    "print(f\"MAE: {mae_svr:.2f}\")\n",
    "print(f\"R²: {r2_svr:.2f}\")\n",
    "\n",
    "# Assume rf and X_test are already defined\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Create a figure and axis for the scatter plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Scatter plot of actual vs. predicted values in green\n",
    "ax.scatter(y_test, y_pred, label='Predictions', color='green', alpha=0.7)\n",
    "\n",
    "# Plot perfect prediction line (45-degree line)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', label='Perfect Prediction')\n",
    "\n",
    "# Set labels and title with SVR performance metrics\n",
    "ax.set_xlabel('Actual Values')\n",
    "ax.set_ylabel('Predicted Values')\n",
    "ax.set_title(f'SVR Performance\\nMSE: {mse_svr:.2f}, MAE: {mae_svr:.2f}, R²: {r2_svr:.2f}')\n",
    "\n",
    "# Legend\n",
    "ax.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b93744-e77e-43a5-9a5d-ee9b2c1a331f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
